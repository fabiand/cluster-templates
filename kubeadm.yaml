apiVersion: v1
kind: Template
metadata:
  name: kube-node
  annotations:
    openshift.io/display-name: "Red Hat Enterprise Linux 7.5 VM"
    description: >-
      This template can be used to create a VM suitable for
      Red Hat Enterprise Linux 7.5.
      The template assumes that a PVC is available which is providing the
      necessary RHEL disk image.
    tags: "kubevirt,virtualmachine,linux,rhel"
    iconClass: "icon-rhel"
    openshift.io/provider-display-name: "KubeVirt"
    openshift.io/documentation-url: "https://github.com/fabiand/common-templates"
    openshift.io/support-url: "https://github.com/fabiand/common-templates/issues"
    template.openshift.io/bindable: "false"
objects:
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    name: ${CLUSTERNAME}
  spec:
    selector:
      matchLabels:
        app: cluster # has to match .spec.template.metadata.labels
    replicas: ${{REPLICAS}} # by default is 1. 1 will be master
    serviceName: node
    template:
      metadata:
        labels:
          app: cluster # has to match .spec.selector.matchLabels
      spec:
        containers:
        - name: vmctl
          image: quay.io/fabiand/vmctl:v0.1.0
          args:
          - "${VMNAME}"
          volumeMounts:
          - name: podinfo
            mountPath: /etc/podinfo
        serviceAccountName: cluster-creator
        volumes:
        - name: podinfo  # For affinity
          downwardAPI:
            items:
            - path: "name"
              fieldRef:
                fieldPath: metadata.name
- apiVersion: v1
  kind: Pod
  metadata:
    name: ${CLUSTERNAME}-client
  spec:
    automountServiceAccountToken: false
    containers:
    - name: vmctl
      image: quay.io/fabiand/vmctl:v0.1.0
      command: ["/usr/bin/sleep"]
      args:
      - "inf"
      volumeMounts:
      - name: clusterinfo
        mountPath: /root/.kube
    volumes:
    - name: clusterinfo
      secret:
        secretName: kubeadm-join-${CLUSTERNAME}
        items:
        - key: kubeconfig
          path: config
- apiVersion: kubevirt.io/v1alpha2
  kind: VirtualMachine
  metadata:
    name: ${VMNAME}
  spec:
    running: false
    template:
      metadata:
        labels:
          role: kubeadm-node
      spec:
        domain:
          cpu:
            cores: 4
          devices:
            disks:
            - disk:
                bus: virtio
              name: rootdisk
              volumeName: rootvolume
            - disk:
                bus: virtio
              name: cloud
              volumeName: cloudinitvolume
            - disk:
                bus: virtio
              name: sa
              serial: underk8ssa
              volumeName: serviceaccount
            interfaces:
            - bridge: {}
              name: default
              model: e1000
            rng: {}
          resources:
            requests:
              memory: 2G
            limits:
              memory: 2.5G
        terminationGracePeriodSeconds: 0
        networks:
        - name: default
          pod: {}
        volumes:
        - name: rootvolume
          ephemeral:
            persistentVolumeClaim:
              claimName: ${PVCNAME}
        - name: cloudinitvolume
          cloudInitNoCloud:
            secretRef:
              name: cloud-config-for-${CLUSTERNAME}
        - serviceAccount:
            serviceAccountName: cluster-creator
          name: serviceaccount
- apiVersion: v1
  kind: Service
  metadata:
    name: api-for-${CLUSTERNAME}
  spec:
    selector:
      role: kubeadm-node
    ports:
    - protocol: TCP
      port: 443
- apiVersion: v1
  kind: Secret
  metadata:
    name: cloud-config-for-${CLUSTERNAME}
  stringData:
    userdata: |
      #cloud-config
      
      password: centos
      chpasswd: {expire: False}
      ssh_pwauth: True
      ssh_authorized_keys:
        - $SSH_PUBKEY
      
      package_upgrade: false
      
      runcmd:
      - |
        KUBERNETES_VER=v1.11.4
        KUBEVIRT_VER=v0.9.3
        PATH=$PATH:/usr/local/bin
        HOME=/root
        
        set -ex
        id

        # from https://kubernetes.io/docs/setup/independent/install-kubeadm/
        {
          yum install -y docker
          systemctl enable --now docker
          
          cat <<EOF > /etc/yum.repos.d/kubernetes.repo
        [kubernetes]
        name=Kubernetes
        baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
        enabled=1
        gpgcheck=1
        repo_gpgcheck=1
        gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
        exclude=kube*
        EOF
          
          setenforce 0
          yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes
          systemctl enable --now kubelet
          
          cat <<EOF >  /etc/sysctl.d/k8s.conf
          net.bridge.bridge-nf-call-ip6tables = 1
          net.bridge.bridge-nf-call-iptables = 1
        EOF
          sysctl --system
        }
        
        # Setup config to access under cluster
        alias underkubectl="kubectl --kubeconfig=$HOME/underkubeconfig"
        {
          mkdir -p /var/run/secrets/kubernetes.io/serviceaccount/ || :
          mount /dev/disk/by-id/virtio-underk8ssa /var/run/secrets/kubernetes.io/serviceaccount/ || :
          underkubectl config set-cluster under --server=https://kubernetes.default.svc.cluster.local --certificate-authority=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
          underkubectl config set-credentials under --token=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
          underkubectl config set-context under --cluster=under --namespace=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace) --user=under
          underkubectl config use-context under
        }

        if [[ "$HOSTNAME" =~ .*-0 ]];
        then
          # Cleanup any old join token
          underkubectl delete secret kubeadm-join-${CLUSTERNAME} || :

          ########
          #
          # Kubernetes with kubeadm
          # coredns is getting killed due to oom
          kubeadm init --pod-network-cidr=10.244.0.0/16 --service-cidr=10.196.0.0/12 --feature-gates CoreDNS=false
          sleep 6

          # Allow easy kubectl login
          mkdir -p $HOME/.kube/
          cp -v /etc/kubernetes/admin.conf $HOME/.kube/config

          # Remove taints in order to allow setup on single master - and then scale up
          sudo kubectl taint nodes --all node-role.kubernetes.io/master-

          # Network plugin
          # http://github.com/kubernetes/kubeadm/issues/1179
          #kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml
          sudo kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
       
          # KubeVirt
          sudo kubectl create configmap -n kube-system kubevirt-config --from-literal debug.useEmulation=true || true
          sudo kubectl apply -f https://github.com/kubevirt/kubevirt/releases/download/$KUBEVIRT_VER/kubevirt.yaml
          #
          ########
  
          # Publish join credentials
          KUBEADMTOKEN=$(kubeadm token create --ttl 1h --print-join-command)
          underkubectl create secret generic kubeadm-join-${CLUSTERNAME} \
            --from-literal="joinCommand=$KUBEADMTOKEN" \
            --from-file="kubeconfig=/etc/kubernetes/admin.conf"
       
        else
        
          kGetConfig() { underkubectl get secret kubeadm-join-${CLUSTERNAME} $@ ; }
          getJoinCmd() { kGetConfig -o=jsonpath='{.data.joinCommand}' | base64 -d ; }

          while [[ -z "$(getJoinCmd)" ]]; do echo -n . ; sleep 6 ; done
          eval "sudo $(getJoinCmd)"

        fi

- apiVersion: v1
  kind: Secret
  metadata:
    name: kubeadm-join-${CLUSTERNAME}
  stringData:
    master: $HOSTNAME
    joinCommand: ""
parameters:
- name: VMNAME
  description: Name of the new VM _template_
  value: kubenode
  required: true
- name: PVCNAME
  description: Name of the PVC with the disk image
  required: true
- name: CLUSTERNAME
  description: Name of the cluster to create or join
  value: kubeadm-cluster
- name: REPLICAS
  description: Number of cluster nodes
  value: "2"
- name: SSH_PUBKEY
  description: Public key to grant access to
